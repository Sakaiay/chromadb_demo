# Chromaç®€å•ä»‹ç»å’Œæ•™ç¨‹
## ä»‹ç»

Chroma æ˜¯ä¸€æ¬¾**AI åŸç”Ÿå¼€æºçš„å‘é‡æ•°æ®åº“**ï¼Œä¸“ä¸ºæœºå™¨å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨è®¾è®¡ï¼Œæ—¨åœ¨é«˜æ•ˆå­˜å‚¨ã€æ£€ç´¢å’ŒåŒ¹é…é«˜ç»´å‘é‡æ•°æ®

## å®‰è£…

ä½¿ç”¨ pip å®‰è£… Chroma

```Bash
pip install chromadb  
```

## åŸºç¡€ä½¿ç”¨å‘½ä»¤

åœ¨**Chroma**ä¸­ï¼Œ**é›†åˆï¼ˆCollectionï¼‰** æ˜¯æ ¸å¿ƒå­˜å‚¨å•å…ƒï¼Œç”¨äºç®¡ç†æ–‡æ¡£ã€å‘é‡åŠå…ƒæ•°æ®ã€‚æ¯ä¸ªé›†åˆï¼ˆCollectionï¼‰ä¸­å­˜å‚¨çš„æ•°æ®æ ¼å¼å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š



![](./img/image1.png)



**`documents`** **ï¼ˆæ–‡æ¡£å†…å®¹ï¼‰ï¼š** å­˜å‚¨åŸå§‹æ–‡æœ¬æˆ–éç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚æ®µè½ã€å¥å­ç­‰ï¼‰ã€‚

**`embeddings`** **ï¼ˆåµŒå…¥å‘é‡ï¼‰ï¼š** æ–‡æ¡£å†…å®¹çš„é«˜ç»´å‘é‡è¡¨ç¤ºï¼Œç”¨äºæ”¯æŒåŸºäºç›¸ä¼¼åº¦çš„æ£€ç´¢ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰ã€‚Chroma å†…ç½®å¤šç§åµŒå…¥æ¨¡å‹ï¼ˆå¦‚ HuggingFaceã€OpenAIï¼‰ï¼Œä¹Ÿå¯è‡ªå®šä¹‰åµŒå…¥å‡½æ•°ã€‚

**`metadatas`** **ï¼ˆå…ƒæ•°æ®ï¼‰ï¼š** é™„åŠ çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œä¾‹å¦‚æ–‡æ¡£æ¥æºã€é¡µç ã€æ—¶é—´æˆ³ç­‰ã€‚è¿™äº›ä¿¡æ¯ç”±ç”¨æˆ·æ‰‹åŠ¨æ·»åŠ ã€‚

**`ids`** **ï¼ˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼‰ï¼š** æ¯ä¸ªæ–‡æ¡£çš„å”¯ä¸€ IDï¼Œéœ€æ»¡è¶³å‘½åè§„åˆ™ï¼šé•¿åº¦ 3-63 å­—ç¬¦ï¼Œä»¥å°å†™å­—æ¯æˆ–æ•°å­—å¼€å¤´ç»“å°¾ï¼Œä¸­é—´å¯åŒ…å«è¿å­—ç¬¦ï¼ˆå¦‚`"doc-001"`ï¼‰ã€‚



### åˆ›å»ºæŒä¹…å®¢æˆ·ç«¯

Chroma æ”¯æŒæŒä¹…åŒ–å­˜å‚¨ï¼Œé€šè¿‡`PersistentClient`æŒ‡å®šæœ¬åœ°è·¯å¾„ä¿å­˜æ•°æ®ï¼Œé¿å…é‡å¯åæ•°æ®ä¸¢å¤±ï¼š

```Python
import chromadb  
client = chromadb.PersistentClient(path="./chroma_db")  # æŒä¹…åŒ–è·¯å¾„
```

### åˆ›å»ºé›†åˆ

é›†åˆæ˜¯ Chroma çš„æ ¸å¿ƒå­˜å‚¨å•å…ƒï¼Œç±»ä¼¼äºæ•°æ®åº“ä¸­çš„è¡¨ã€‚

```Python
collection = client.create_collection(  
    name="my_collection",  
    embedding_function=embedding_model  # å¯é€‰åµŒå…¥å‡½æ•°
)  
```

**æ³¨æ„ï¼š**å¦‚æœåˆ›å»ºé›†åˆçš„æ—¶å€™ä¸æŒ‡å®š`embedding_function`ï¼Œé‚£ä¹ˆæ·»åŠ æ•°æ®çš„æ—¶å€™å¿…é¡»æ‰‹åŠ¨åŠ å…¥`embeddings`ã€‚

### åˆ é™¤é›†åˆ

```Python
client.delete_collection(name="my_collection")  
```

### æ·»åŠ æ•°æ®

é€šè¿‡`.add()`æ–¹æ³•æ’å…¥æ–‡æ¡£ã€å‘é‡ã€å…ƒæ•°æ®åŠå”¯ä¸€ IDï¼š

```Python
collection.add(  
    documents=["äººå·¥æ™ºèƒ½æ˜¯æœªæ¥çš„æ ¸å¿ƒæŠ€æœ¯ã€‚", "Chroma æ˜¯é«˜æ•ˆçš„å‘é‡æ•°æ®åº“ã€‚"],  
    metadatas=[{"source": "book1"}, {"source": "article2"}],  # å¯é€‰å…ƒæ•°æ® 
    ids=["doc1", "doc2"]  # å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œéœ€ç¬¦åˆå‘½åè§„åˆ™
)  
```

**æ³¨æ„ï¼š**å¦‚æœåˆ›å»ºé›†åˆçš„æ—¶å€™æ²¡æœ‰æŒ‡å®š`embedding_function`ï¼Œæ·»åŠ æ•°æ®çš„æ—¶å€™å¿…é¡»åŠ å…¥embeddingså‚æ•°ã€‚

### åˆ é™¤æ•°æ®

é€šè¿‡`.delete()`æ–¹æ³•ç§»é™¤æŒ‡å®š ID æˆ–åŒ¹é…æ¡ä»¶çš„æ–‡æ¡£ï¼š

```Python
collection.delete(ids=["doc1"])  # æŒ‰ ID åˆ é™¤ 
# æˆ–æŒ‰æ¡ä»¶åˆ é™¤  
collection.delete(where={"source": "article2"})  # æŒ‰å…ƒæ•°æ®è¿‡æ»¤åˆ é™¤  
```

### æŸ¥è¯¢æ•°æ®

é€šè¿‡`.query()`å®ç°ç›¸ä¼¼æ€§æœç´¢æˆ–æ¡ä»¶è¿‡æ»¤ï¼š

```Python
results = collection.query(  
    query_texts=["å‘é‡æ•°æ®åº“"],  # æŸ¥è¯¢æ–‡æœ¬  
    n_results=2,  # è¿”å›æœ€ç›¸ä¼¼çš„ 2 æ¡ç»“æœ 
    where={"source": "book1"}  # å¯é€‰è¿‡æ»¤æ¡ä»¶ 
)  
print(results["documents"])  # è¾“å‡ºåŒ¹é…çš„æ–‡æ¡£  
```



## è¿›é˜¶ä½¿ç”¨

Chromaç°åœ¨å¤§å¤šå’ŒLLMç»“åˆä½¿ç”¨ç”¨äºæ„å»ºRAGï¼ŒLangchainå°±å°è£…äº†Chromaæ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨ï¼Œå…·ä½“å¯ä»¥å‚è€ƒå®˜ç½‘ï¼š[Chroma | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/integrations/vectorstores/chroma/)

ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨æˆ‘ä¹Ÿå¯¹chromaè¿›è¡ŒäºŒæ¬¡å°è£…ï¼Œç»“åˆäº†embeddingæ¨¡å‹ã€‚

é¦–å…ˆæˆ‘å°è£…äº†embeddingç±»ï¼Œæ”¯æŒç¦»çº¿å’Œåœ¨çº¿

```Python
# CustomEmbedding.py
import os
import openai
from typing import Union, List

class EmbeddingModel:
    def __init__(
        self,
        model_name: str,
        model_path: str, 
        url: str = None,
        api_key: str = None
    ):
        if url or api_key:
            # APIæ¨¡å¼
            if not all([url, api_key]):
                raise ValueError("API mode need url and api_key")
            
            self.mode = "api"
            self.client = openai.Client(base_url=url, api_key=api_key)
            self.model_name = model_name
            
        else:
            # æœ¬åœ°æ¨¡å¼
            self.model_path = model_path
            self.mode = "local"
            try:
                from sentence_transformers import SentenceTransformer
            except ImportError:
                raise ImportError("install sentence-transformersï¼špip install sentence-transformers")
            
            self.model = SentenceTransformer(self.model_path)
            self.embedding_dimension = self.model.get_sentence_embedding_dimension()

    def generate_embeddings_batch(self, texts: Union[str, List[str]]) -> List[List[float]]:
        if self.mode == "api":
            response = self.client.embeddings.create(
                model=self.model_name,
                input=texts
            )
            return [item.embedding for item in response.data]
        else:
            embeddings = self.model.encode(texts, convert_to_tensor=False)
            return embeddings.tolist()
        
    def generate_embeddings(self, texts: Union[str, List[str]]):
        if isinstance(texts, str):
            texts = [texts]
            
        BATCH_SIZE = 1000
        embeddings = []
        for i in range(0, len(texts), BATCH_SIZE):
            batch = texts[i:i+BATCH_SIZE]
            batch_embeddings = self.generate_embeddings_batch(batch)
            embeddings.extend(batch_embeddings)
        
        return embeddings
    
```

ç„¶åå°è£…chromaï¼Œç”¨äºä¸chromadbäº¤äº’

```Python
import chromadb
from CustomEmbedding import EmbeddingModel

import uuid
from chromadb.config import Settings
from typing import Union, List, Dict

class ChromaDBManager:
    def __init__(self, 
                 embedding_model, 
                 persist_directory="./chroma_db"):
        '''
            åˆå§‹åŒ–Chromaæ•°æ®åº“å®¢æˆ·ç«¯
        '''
        self.client = chromadb.PersistentClient(path=persist_directory)
        self.embedding_model = embedding_model
    
    def get_collections_list(self) -> List[str]:
        """
            è·å–æ‰€æœ‰é›†åˆçš„åç§°
        """
        return [collection.name for collection in self.client.list_collections()]
    
    def get_collection(self, collection_name: str):
        """
            è·å–æŒ‡å®šåç§°çš„é›†åˆ
        """
        collections = {collection.name: collection for collection in self.client.list_collections()}
        return collections.get(collection_name)
    
    def create_collection(self, collection_name: str):
        """
            åˆ›å»ºä¸€ä¸ªæ–°çš„é›†åˆ
        """
        if collection_name not in self.get_collections_list():
            self.client.create_collection(name=collection_name)
        return self.get_collection(collection_name)
    
    def delete_collection(self, collection_name: str):
        ''' 
           åˆ é™¤æŒ‡å®šé›†åˆ
        '''
        if collection_name not in self.get_collections_list():
            raise ValueError(f"Delete Error: Collection '{collection_name}' does not exist.")
        self.client.delete_collection(name=collection_name)
    
    def add_texts(self, 
                  collection_name: str, 
                  texts: List[str], 
                  metadatas: List[Dict]) -> List[Dict]:
        """
            æ·»åŠ æ–‡æœ¬åŠå…¶åµŒå…¥å‘é‡åˆ°æŒ‡å®šé›†åˆä¸­ï¼Œå¹¶è¿”å›ç”Ÿæˆçš„ID
        """
        collection = self.get_collection(collection_name)
        if not collection:
            raise ValueError(f"Collection '{collection_name}' does not exist. Please create it first.")

        doc_infos = []
        ids = [str(uuid.uuid1()) for _ in range(len(texts))]
        embeddings = self.embedding_model.generate_embeddings(texts)
        for _id, text, embedding, metadata in zip(ids, texts, embeddings, metadatas):
            collection.add(
                ids=_id,
                embeddings=embedding,
                metadatas=metadata,
                documents=text
            )
            doc_infos.append({"id": _id, "metadata": metadata})
        return doc_infos
    
    
    def get_collection_texts(self, collection_name: str) -> List[Dict]:
        """
            è·å¾—æŒ‡å®šé›†åˆæ‰€æœ‰æ•°æ®
        """
        collection = self.get_collection(collection_name)
        if not collection:
            raise ValueError(f"Collection '{collection_name}' does not exist.")

        results = collection.get()
        return [
            {
                "id": id_,
                "text": document,
                "metadata": metadata
            }
            for id_, document, metadata in zip(results["ids"], results["documents"], results["metadatas"])
        ]
    
    def delete_texts(self, 
                     collection_name: str, 
                     ids: List[str]):
        """
            ä»æŒ‡å®šé›†åˆä¸­åˆ é™¤æŒ‡å®šIDçš„æ–‡æœ¬
        """
        collection = self.get_collection(collection_name)
        if not collection:
            raise ValueError(f"Collection '{collection_name}' does not exist.")
        collection.delete(ids=ids)
    
    def upsert_texts(self,
                     collection_name: str, 
                     texts: List[str], 
                     metadatas: List[Dict],
                     ids: List[str] = None,
                     ):
        ''' 
           æ›´æ–°æŒ‡å®šé›†åˆä¸­æ–‡æœ¬
           å¦‚æœIDå­˜åœ¨å°±æ›´æ–°å­˜åœ¨çš„æ–‡æœ¬ï¼Œå¦‚æœIDä¸å­˜åœ¨å°±æ’å…¥æ–°çš„æ–‡æœ¬
        '''
        collection = self.get_collection(collection_name)
        if not collection:
            raise ValueError(f"Collection '{collection_name}' does not exist.")
        
        if not ids:
            ids = [str(uuid.uuid1()) for _ in range(len(texts))]
        doc_infos = []
        embeddings = self.embedding_model.generate_embeddings(texts)
        for _id, text, embedding, metadata in zip(ids, texts, embeddings, metadatas):
            collection.upsert(
                ids=_id,
                embeddings=embedding,
                metadatas=metadata,
                documents=text
            )
            doc_infos.append({"id": _id, "metadata": metadata})
        return doc_infos
    
    
    def query_texts(self, 
                    collection_name: str, 
                    query_text: str, 
                    n_results: int = 3) -> List[Dict]:
        """
            æ ¹æ®æŸ¥è¯¢æ–‡æœ¬æ£€ç´¢æŒ‡å®šé›†åˆä¸­çš„ç›¸ä¼¼æ–‡æœ¬
        """
        collection = self.get_collection(collection_name)
        if not collection:
            raise ValueError(f"Collection '{collection_name}' does not exist.")

        query_embedding = self.embedding_model.generate_embeddings(query_text)
        results = collection.query(
            query_embeddings=query_embedding,
            n_results=n_results
        )
        return [
            {
                "id": id_,
                "text": document,
                "metadata": metadata
            }
            for id_, document, metadata in zip(results["ids"][0], results["documents"][0], results["metadatas"][0])
        ]
        
    
   
```

### åˆå§‹åŒ–embeddingï¼Œchromaå’Œæ•°æ®

ä½¿ç”¨çš„æ—¶å€™å¿…é¡»åˆå§‹åŒ–`embedding`ç±»ã€‚

```Python
model_name = "bge-m3"
model_path =  "xxxxx/bge-m3"
url = "http://127.0.0.1:9997/v1"
api_key = "EMPTY"
myembedding = EmbeddingModel(model_name=model_name, 
               model_path=model_path, 
               url=url, 
               api_key=api_key)
```

åˆå§‹åŒ–ä¸¤ç§æ•°æ®ï¼Œ**sports**å’Œ**city**

```Python
texts_sports = [
        "2011å¹´7æœˆ20æ—¥ï¼Œå§šæ˜æ­£å¼å®£å¸ƒé€€å½¹",
         "1998å¹´4æœˆï¼Œå§šæ˜å…¥é€‰ç‹éæ‰§æ•™çš„å›½å®¶é˜Ÿï¼Œå¼€å§‹äº†èŒä¸šç¯®çƒç”Ÿæ¶¯ã€‚",
         "æ²™å¥å°”Â·å¥¥å°¼å°”ï¼ˆShaquille O'Nealï¼‰ï¼Œå…¨åæ²™å¥å°”Â·é›·è‚–æ©Â·å¥¥å°¼å°”ï¼ˆShaquille Rashaun O'Nealï¼‰ï¼Œæ˜µç§°æ²™å…‹ï¼ˆShaqï¼‰",
        "å¥¥å°¼å°”åœ¨1992å¹´NBAé€‰ç§€ä¸­äºç¬¬1è½®ç¬¬1ä½ä»¥çŠ¶å…ƒç§€çš„èº«ä»½è¢«å¥¥å…°å¤šé­”æœ¯é˜Ÿé€‰ä¸­"
]
metadatas_sports = [{'domain': 'sports', 'source': idx} for idx in range(len(texts_sports))]


texts_city = [
    "åŒ—äº¬å¸‚ï¼ˆBeijingï¼‰ï¼Œç®€ç§°â€œäº¬â€ï¼Œå¤ç§°ç‡•äº¬ã€åŒ—å¹³ï¼Œæ˜¯ä¸­åäººæ°‘å…±å’Œå›½é¦–éƒ½ã€ç›´è¾–å¸‚ã€å›½å®¶ä¸­å¿ƒåŸå¸‚ã€è¶…å¤§åŸå¸‚",
    "2023å¹´ï¼ŒåŒ—äº¬å¸‚å…¨å¹´å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼43760.7äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.2%",
    "çº½çº¦ï¼ˆè‹±è¯­ï¼šNew Yorkï¼‰ï¼Œä½äºç¾å›½çº½çº¦å·å—ç«¯ï¼ˆéçº½çº¦å·é¦–åºœï¼‰ï¼Œä¸ºç¾å›½äººå£æœ€å¤šçš„åŸå¸‚ã€çº½çº¦éƒ½ä¼šåŒºçš„æ ¸å¿ƒ",
    "çº½çº¦ä½äºç¾å›½ä¸œåŒ—éƒ¨ï¼Œæ»¨ä¸´å¤§è¥¿æ´‹æµ·å²¸ï¼Œåæ‹¥ä¸–ç•Œä¸Šæœ€å¤§å¤©ç„¶æ¸¯å£ä¹‹ä¸€çš„çº½çº¦å’Œæ–°æ³½è¥¿æ¸¯"
]
metadatas_city = [{'domain': 'city', 'source': idx} for idx in range(len(texts_city))]
```

åˆå§‹åŒ–`chroma`ç±»

```Python
db_manager = ChromaDBManager(embedding_model=myembedding)
```

### æ·»åŠ é›†åˆ

æ·»åŠ `collection`ï¼Œæ·»åŠ ä¸¤ä¸ª`collection`ï¼Œåˆ†ä¸ºä¸º**sports**å’Œ**city**

```Python
collection_sports = "sports"
db_manager.create_collection(collection_sports)
doc_infos_sports = db_manager.add_texts(collection_sports, 
                                  texts_sports, 
                                  metadatas_sports)

collection_city = "city"
db_manager.create_collection(collection_city)
doc_infos_city = db_manager.add_texts(collection_city, 
                                  texts_city, 
                                  metadatas_city)


```

### æŸ¥çœ‹é›†åˆ

æŸ¥çœ‹ä¸€ä¸‹ç°åœ¨æœ‰ä»€ä¹ˆé›†åˆ

```Python
collection_list = db_manager.get_collections_list()
print(collection_list)
# ['city', 'sports']
```

### æŸ¥è¯¢é›†åˆ

æŸ¥è¯¢é›†åˆï¼Œé—®ï¼š** 'å¥¥å°¼å°”é€‰ç§€'**ï¼Œå¹¶ä¸”æŒ‡å®šæŸ¥è¯¢**sports**é›†åˆ

```Python
query = 'å¥¥å°¼å°”é€‰ç§€'

query_res = db_manager.query_texts(
    collection_name='sports',
    query_text=query,
    n_results=1
)
print(query_res)
'''
 [{'id': 'da433748-258c-11f0-9f61-3cecefb2262e', 
'text': 'å¥¥å°¼å°”åœ¨1992å¹´NBAé€‰ç§€ä¸­äºç¬¬1è½®ç¬¬1ä½ä»¥çŠ¶å…ƒç§€çš„èº«ä»½è¢«å¥¥å…°å¤šé­”æœ¯é˜Ÿé€‰ä¸­',
 'metadata': {'domain': 'sports', 'source': 3}}]
'''
```

### åˆ é™¤é›†åˆ

åˆ é™¤**sports**é›†åˆ

```Python
db_manager.delete_collection(collection_name='sports')
```

æˆ‘ä»¬å†çœ‹ä¸€ä¸‹æœ‰ä»€ä¹ˆ**collection**ï¼Œ**sports**é›†åˆè¢«åˆ é™¤äº†ï¼Œç°åœ¨è¿˜æœ‰**city**é›†åˆ


```Python
collection_list = db_manager.get_collections_list()
print(collection_list)
# ['city']
```

### è·å¾—collectionä¸­æ‰€æœ‰çš„æ•°æ®

è¿”å›idã€textå’Œmetadata


```Python
collection_results = db_manager.get_collection_texts(collection_name='city')
for collection_result in collection_results:
    print(collection_result)

{'id': '0f04c0be-258d-11f0-9f61-3cecefb2262e', 'text': 'åŒ—äº¬å¸‚ï¼ˆBeijingï¼‰ï¼Œç®€ç§°â€œäº¬â€ï¼Œå¤ç§°ç‡•äº¬ã€åŒ—å¹³ï¼Œæ˜¯ä¸­åäººæ°‘å…±å’Œå›½é¦–éƒ½ã€ç›´è¾–å¸‚ã€å›½å®¶ä¸­å¿ƒåŸå¸‚ã€è¶…å¤§åŸå¸‚', 'metadata': {'domain': 'city', 'source': 0}}  
{'id': '0f04c172-258d-11f0-9f61-3cecefb2262e', 'text': '2023å¹´ï¼ŒåŒ—äº¬å¸‚å…¨å¹´å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼43760.7äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.2%', 'metadata': {'domain': 'city', 'source': 1}}  
{'id': '0f04c1d6-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ï¼ˆè‹±è¯­ï¼šNew Yorkï¼‰ï¼Œä½äºç¾å›½çº½çº¦å·å—ç«¯ï¼ˆéçº½çº¦å·é¦–åºœï¼‰ï¼Œä¸ºç¾å›½äººå£æœ€å¤šçš„åŸå¸‚ã€çº½çº¦éƒ½ä¼šåŒºçš„æ ¸å¿ƒ', 'metadata': {'domain': 'city', 'source': 2}}  
{'id': '0f04c226-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ä½äºç¾å›½ä¸œåŒ—éƒ¨ï¼Œæ»¨ä¸´å¤§è¥¿æ´‹æµ·å²¸ï¼Œåæ‹¥ä¸–ç•Œä¸Šæœ€å¤§å¤©ç„¶æ¸¯å£ä¹‹ä¸€çš„çº½çº¦å’Œæ–°æ³½è¥¿æ¸¯', 'metadata': {'domain': 'city', 'source': 3}}
```

### åˆ é™¤collectionä¸­çš„æŒ‡å®šæ•°æ®

```Python
id_list = ['0f04c0be-258d-11f0-9f61-3cecefb2262e', '0f04c172-258d-11f0-9f61-3cecefb2262e']
db_manager.delete_texts('city', id_list)

collection_results = db_manager.get_collection_texts(collection_name='city')
for collection_result in collection_results:
    print(collection_result)
{'id': '0f04c1d6-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ï¼ˆè‹±è¯­ï¼šNew Yorkï¼‰ï¼Œä½äºç¾å›½çº½çº¦å·å—ç«¯ï¼ˆéçº½çº¦å·é¦–åºœï¼‰ï¼Œä¸ºç¾å›½äººå£æœ€å¤šçš„åŸå¸‚ã€çº½çº¦éƒ½ä¼šåŒºçš„æ ¸å¿ƒ', 'metadata': {'domain': 'city', 'source': 2}}
{'id': '0f04c226-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ä½äºç¾å›½ä¸œåŒ—éƒ¨ï¼Œæ»¨ä¸´å¤§è¥¿æ´‹æµ·å²¸ï¼Œåæ‹¥ä¸–ç•Œä¸Šæœ€å¤§å¤©ç„¶æ¸¯å£ä¹‹ä¸€çš„çº½çº¦å’Œæ–°æ³½è¥¿æ¸¯', 'metadata': {'domain': 'city', 'source': 3}}


```

### ä¿®æ”¹collectionä¸­çš„æ–‡æœ¬

å¦‚æœæä¾›IDå°±æ›´æ–°IDå¯¹åº”çš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰æä¾›IDå°±æ’å…¥æ–°çš„æ–‡æœ¬  
ä¸‹é¢é¦–å…ˆæ¼”ç¤ºä¸€ä¸‹æ²¡æœ‰æä¾›IDçš„æƒ…å†µï¼šéœ€è¦æä¾›æ–°çš„æ–‡æœ¬å’Œmetadataä¿¡æ¯

```Python
texts_city2 = [
    "ä¸Šæµ·å¸‚åœ°å¤„é•¿æ±Ÿä¸‰è§’æ´²å†²ç§¯å¹³åŸï¼Œåœ°åŠ¿å¦è¡ä½å¹³ï¼Œ å±äºšçƒ­å¸¦å­£é£æ€§æ°”å€™ï¼Œæœ€å¤§æ²³æµä¸ºé»„æµ¦æ±Ÿã€‚",
    "2024å¹´ï¼Œä¸Šæµ·å¸‚å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼53926.71äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.0%ã€‚",
    "ä¸Šæµ·å¸‚æ˜¯ä¸­å›½å›½é™…ç»æµã€é‡‘èã€è´¸æ˜“ã€èˆªè¿ã€ç§‘æŠ€åˆ›æ–°ä¸­å¿ƒï¼Œç¬¬ä¸‰äº§ä¸šä¸ºå…¶æ”¯æŸ±äº§ä¸šï¼Œæœ‰ç€å¤–è´¸ç‰©æµã€é‡‘èä¿é™©ä¸šã€ä¿¡æ¯æœåŠ¡ä¸šã€æ—…æ¸¸ä¸šã€æˆ¿åœ°äº§ä¸šå’Œå…¶ä»–æ–°å…´æœåŠ¡ä¸šï¼Œ æˆä¸ºæ‹‰åŠ¨ç»æµå¢é•¿â€œä¸»åŠ¨åŠ›â€"
    ]
metadatas_city2 = [{'domain': 'city2', 'source': idx} for idx in range(len(texts_city2))]
db_manager.upsert_texts(collection_name='city', texts=texts_city2, metadatas=metadatas_city2)

[{'id': 'cce06eb6-258e-11f0-9f61-3cecefb2262e',
  'metadata': {'domain': 'city2', 'source': 0}},
 {'id': 'cce06f92-258e-11f0-9f61-3cecefb2262e',
  'metadata': {'domain': 'city2', 'source': 1}},
 {'id': 'cce06ff6-258e-11f0-9f61-3cecefb2262e',
  'metadata': {'domain': 'city2', 'source': 2}}]
```

æ’å…¥æ–°æ•°æ®åå†æŸ¥çœ‹ä¸€ä¸‹é›†åˆå†…çš„æ‰€æœ‰æ–‡æœ¬ï¼Œå‘ç°æ’å…¥è¿›å»äº†

```Python
collection_results = db_manager.get_collection_texts(collection_name='city')
for collection_result in collection_results:
    print(collection_result)

{'id': '0f04c1d6-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ï¼ˆè‹±è¯­ï¼šNew Yorkï¼‰ï¼Œä½äºç¾å›½çº½çº¦å·å—ç«¯ï¼ˆéçº½çº¦å·é¦–åºœï¼‰ï¼Œä¸ºç¾å›½äººå£æœ€å¤šçš„åŸå¸‚ã€çº½çº¦éƒ½ä¼šåŒºçš„æ ¸å¿ƒ', 'metadata': {'domain': 'city', 'source': 2}}
{'id': '0f04c226-258d-11f0-9f61-3cecefb2262e', 'text': 'çº½çº¦ä½äºç¾å›½ä¸œåŒ—éƒ¨ï¼Œæ»¨ä¸´å¤§è¥¿æ´‹æµ·å²¸ï¼Œåæ‹¥ä¸–ç•Œä¸Šæœ€å¤§å¤©ç„¶æ¸¯å£ä¹‹ä¸€çš„çº½çº¦å’Œæ–°æ³½è¥¿æ¸¯', 'metadata': {'domain': 'city', 'source': 3}}
{'id': 'cce06eb6-258e-11f0-9f61-3cecefb2262e', 'text': 'ä¸Šæµ·å¸‚åœ°å¤„é•¿æ±Ÿä¸‰è§’æ´²å†²ç§¯å¹³åŸï¼Œåœ°åŠ¿å¦è¡ä½å¹³ï¼Œ å±äºšçƒ­å¸¦å­£é£æ€§æ°”å€™ï¼Œæœ€å¤§æ²³æµä¸ºé»„æµ¦æ±Ÿã€‚', 'metadata': {'domain': 'city2', 'source': 0}}
{'id': 'cce06f92-258e-11f0-9f61-3cecefb2262e', 'text': '2024å¹´ï¼Œä¸Šæµ·å¸‚å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼53926.71äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.0%ã€‚', 'metadata': {'domain': 'city2', 'source': 1}}
{'id': 'cce06ff6-258e-11f0-9f61-3cecefb2262e', 'text': 'ä¸Šæµ·å¸‚æ˜¯ä¸­å›½å›½é™…ç»æµã€é‡‘èã€è´¸æ˜“ã€èˆªè¿ã€ç§‘æŠ€åˆ›æ–°ä¸­å¿ƒï¼Œç¬¬ä¸‰äº§ä¸šä¸ºå…¶æ”¯æŸ±äº§ä¸šï¼Œæœ‰ç€å¤–è´¸ç‰©æµã€é‡‘èä¿é™©ä¸šã€ä¿¡æ¯æœåŠ¡ä¸šã€æ—…æ¸¸ä¸šã€æˆ¿åœ°äº§ä¸šå’Œå…¶ä»–æ–°å…´æœåŠ¡ä¸šï¼Œ æˆä¸ºæ‹‰åŠ¨ç»æµå¢é•¿â€œä¸»åŠ¨åŠ›â€', 'metadata': {'domain': 'city2', 'source': 2}}

```

ä¸‹é¢è¯•ä¸€ä¸‹æä¾›IDï¼Œä¿®æ”¹ç°æœ‰çš„æ–‡æœ¬


```Python
ids = ['0f04c1d6-258d-11f0-9f61-3cecefb2262e', '0f04c226-258d-11f0-9f61-3cecefb2262e']
texts_city3 = ['åŒ—äº¬å¸‚ï¼ˆBeijingï¼‰ï¼Œç®€ç§°â€œäº¬â€ï¼Œå¤ç§°ç‡•äº¬ã€åŒ—å¹³ï¼Œæ˜¯ä¸­åäººæ°‘å…±å’Œå›½é¦–éƒ½ã€ç›´è¾–å¸‚ã€å›½å®¶ä¸­å¿ƒåŸå¸‚ã€è¶…å¤§åŸå¸‚',
               '2023å¹´ï¼ŒåŒ—äº¬å¸‚å…¨å¹´å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼43760.7äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.2%']
metadatas_city3 = [{'domain': 'city', 'source': 2}, {'domain': 'city', 'source': 3}]

db_manager.upsert_texts(collection_name='city', texts=texts_city3, metadatas=metadatas_city3, ids=ids)
[{'id': '0f04c1d6-258d-11f0-9f61-3cecefb2262e',
  'metadata': {'domain': 'city', 'source': 2}},
 {'id': '0f04c226-258d-11f0-9f61-3cecefb2262e',
  'metadata': {'domain': 'city', 'source': 3}}]

```

æŸ¥çœ‹ä¸€ä¸‹ä¿®æ”¹çš„ç»“æœï¼Œæˆ‘ä»¬æŠŠçº½çº¦çš„ä¿¡æ¯ï¼Œå…¨éƒ¨ä¿®æ”¹æˆäº†åŒ—äº¬


```Python
collection_results = db_manager.get_collection_texts(collection_name='city')
for collection_result in collection_results:
    print(collection_result)
{'id': '0f04c1d6-258d-11f0-9f61-3cecefb2262e', 'text': 'åŒ—äº¬å¸‚ï¼ˆBeijingï¼‰ï¼Œç®€ç§°â€œäº¬â€ï¼Œå¤ç§°ç‡•äº¬ã€åŒ—å¹³ï¼Œæ˜¯ä¸­åäººæ°‘å…±å’Œå›½é¦–éƒ½ã€ç›´è¾–å¸‚ã€å›½å®¶ä¸­å¿ƒåŸå¸‚ã€è¶…å¤§åŸå¸‚', 'metadata': {'domain': 'city', 'source': 2}}
{'id': '0f04c226-258d-11f0-9f61-3cecefb2262e', 'text': '2023å¹´ï¼ŒåŒ—äº¬å¸‚å…¨å¹´å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼43760.7äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.2%', 'metadata': {'domain': 'city', 'source': 3}}
{'id': 'cce06eb6-258e-11f0-9f61-3cecefb2262e', 'text': 'ä¸Šæµ·å¸‚åœ°å¤„é•¿æ±Ÿä¸‰è§’æ´²å†²ç§¯å¹³åŸï¼Œåœ°åŠ¿å¦è¡ä½å¹³ï¼Œ å±äºšçƒ­å¸¦å­£é£æ€§æ°”å€™ï¼Œæœ€å¤§æ²³æµä¸ºé»„æµ¦æ±Ÿã€‚', 'metadata': {'domain': 'city2', 'source': 0}}
{'id': 'cce06f92-258e-11f0-9f61-3cecefb2262e', 'text': '2024å¹´ï¼Œä¸Šæµ·å¸‚å®ç°åœ°åŒºç”Ÿäº§æ€»å€¼53926.71äº¿å…ƒï¼ŒæŒ‰ä¸å˜ä»·æ ¼è®¡ç®—ï¼Œæ¯”ä¸Šå¹´å¢é•¿5.0%ã€‚', 'metadata': {'domain': 'city2', 'source': 1}}
{'id': 'cce06ff6-258e-11f0-9f61-3cecefb2262e', 'text': 'ä¸Šæµ·å¸‚æ˜¯ä¸­å›½å›½é™…ç»æµã€é‡‘èã€è´¸æ˜“ã€èˆªè¿ã€ç§‘æŠ€åˆ›æ–°ä¸­å¿ƒï¼Œç¬¬ä¸‰äº§ä¸šä¸ºå…¶æ”¯æŸ±äº§ä¸šï¼Œæœ‰ç€å¤–è´¸ç‰©æµã€é‡‘èä¿é™©ä¸šã€ä¿¡æ¯æœåŠ¡ä¸šã€æ—…æ¸¸ä¸šã€æˆ¿åœ°äº§ä¸šå’Œå…¶ä»–æ–°å…´æœåŠ¡ä¸šï¼Œ æˆä¸ºæ‹‰åŠ¨ç»æµå¢é•¿â€œä¸»åŠ¨åŠ›â€', 'metadata': {'domain': 'city2', 'source': 2}}

```
## å‚è€ƒ

[Introduction - Chroma Docs](https://docs.trychroma.com/docs/overview/introduction)